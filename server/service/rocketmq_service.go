package service

import (
	"context"
	"fmt"
	"log"
	"sync"
	"time"

	"go_rocketmq_sdk/proto"
	"go_rocketmq_sdk/server/config"
	"go_rocketmq_sdk/server/metrics"

	"github.com/apache/rocketmq-client-go/v2"
	"github.com/apache/rocketmq-client-go/v2/consumer"
	"github.com/apache/rocketmq-client-go/v2/primitive"
	"github.com/apache/rocketmq-client-go/v2/producer"
	"github.com/google/uuid"
	"google.golang.org/grpc/codes"
	"google.golang.org/grpc/status"
)

// ProducerInfo ç”Ÿäº§è€…ä¿¡æ¯
type ProducerInfo struct {
	Producer   rocketmq.Producer
	Topic      string
	Endpoint   string
	InstanceId string
	RefCount   int       // å¼•ç”¨è®¡æ•°ï¼Œæ”¯æŒå¤ç”¨
	LastActive time.Time // æœ€åæ´»è·ƒæ—¶é—´ï¼Œç”¨äºè¶…æ—¶æ¸…ç†
	CreatedAt  time.Time // åˆ›å»ºæ—¶é—´
}

// ConsumerInfo æ¶ˆè´¹è€…ä¿¡æ¯
type ConsumerInfo struct {
	Consumer    rocketmq.PushConsumer
	Topics      map[string]bool // æ”¹ä¸ºæ”¯æŒå¤šä¸ªTopicçš„æ˜ å°„
	GroupID     string
	Endpoint    string
	InstanceId  string
	MessageChan chan *proto.Message
	CancelFunc  context.CancelFunc // ç”¨äºå–æ¶ˆæ¶ˆè´¹è€…ä¸Šä¸‹æ–‡
	LastActive  time.Time          // æœ€åæ´»è·ƒæ—¶é—´
	RefCount    int                // å¼•ç”¨è®¡æ•°ï¼Œæ”¯æŒå¤ç”¨
	CreatedAt   time.Time          // åˆ›å»ºæ—¶é—´
}

// ConnectionKey è¿æ¥å”¯ä¸€æ ‡è¯†
type ConnectionKey struct {
	Endpoint    string
	AccessKeyId string
	InstanceId  string
	Topic       string
}

// ConsumerKey æ¶ˆè´¹è€…è¿æ¥å”¯ä¸€æ ‡è¯† - æ”¯æŒä¸åŒRocketMQå®ä¾‹
type ConsumerKey struct {
	Endpoint    string
	AccessKeyId string
	InstanceId  string
	GroupID     string // æŒ‰GroupID+Endpointå¤ç”¨ï¼Œæ”¯æŒä¸åŒRocketMQå®ä¾‹
}

// RocketMQProxyService gRPCæœåŠ¡å®ç°
type RocketMQProxyService struct {
	proto.UnimplementedRocketMQProxyServer
	producers       map[string]*ProducerInfo // producer_id -> ProducerInfo
	consumers       map[string]*ConsumerInfo // consumer_id -> ConsumerInfo
	sharedProducers map[ConnectionKey]string // è¿æ¥é…ç½® -> producer_id (æ”¯æŒå¤šå®ä¾‹)
	sharedConsumers map[ConsumerKey]string   // æ¶ˆè´¹è€…é…ç½® -> consumer_id (æ”¯æŒå¤ç”¨)
	mu              sync.RWMutex
	config          *config.ServerConfig // æœåŠ¡é…ç½®
}

// NewRocketMQProxyService åˆ›å»ºæ–°çš„æœåŠ¡å®ä¾‹
func NewRocketMQProxyService(cfg *config.ServerConfig) *RocketMQProxyService {
	return &RocketMQProxyService{
		producers:       make(map[string]*ProducerInfo),
		consumers:       make(map[string]*ConsumerInfo),
		sharedProducers: make(map[ConnectionKey]string),
		sharedConsumers: make(map[ConsumerKey]string),
		config:          cfg,
	}
}

// CreateProducer åˆ›å»ºç”Ÿäº§è€…
func (s *RocketMQProxyService) CreateProducer(ctx context.Context, req *proto.CreateProducerRequest) (*proto.CreateProducerResponse, error) {
	log.Printf("Creating producer for topic: %s, instance: %s, endpoint: %s", req.Topic, req.InstanceId, req.Endpoint)

	// ç”Ÿæˆè¿æ¥keyï¼Œæ”¯æŒå¤šä¸ªRocketMQå®ä¾‹
	connKey := ConnectionKey{
		Endpoint:    req.Endpoint,
		AccessKeyId: req.AccessKeyId,
		InstanceId:  req.InstanceId,
		Topic:       req.Topic,
	}

	s.mu.Lock()
	defer s.mu.Unlock()

	// æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒé…ç½®çš„ç”Ÿäº§è€…å¯ä»¥å¤ç”¨
	if existingProducerID, exists := s.sharedProducers[connKey]; exists {
		if producerInfo, found := s.producers[existingProducerID]; found {
			// ç”Ÿæˆæ–°çš„IDä½†å¤ç”¨åŒä¸€ä¸ªç”Ÿäº§è€…å®ä¾‹
			newProducerID := uuid.New().String()
			s.producers[newProducerID] = &ProducerInfo{
				Producer:   producerInfo.Producer,
				Topic:      producerInfo.Topic,
				Endpoint:   producerInfo.Endpoint,
				InstanceId: producerInfo.InstanceId,
				RefCount:   producerInfo.RefCount + 1,
				LastActive: producerInfo.LastActive,
				CreatedAt:  producerInfo.CreatedAt,
			}
			producerInfo.RefCount++

			log.Printf("âœ… Reusing producer: ID=%s, Topic=%s, Instance=%s, RefCount=%d",
				newProducerID, req.Topic, req.InstanceId, producerInfo.RefCount)
			return &proto.CreateProducerResponse{
				Success:    true,
				Message:    fmt.Sprintf("Producer reused (ref: %d)", producerInfo.RefCount),
				ProducerId: newProducerID,
			}, nil
		}
	}

	// åˆ›å»ºæ–°çš„ç”Ÿäº§è€…
	// ä½¿ç”¨ç®€å•çš„ç”Ÿäº§è€…ç»„åï¼Œä¸åŒ…å«å®ä¾‹ID
	producerGroup := fmt.Sprintf("grpc_proxy_producer_%d", time.Now().UnixNano())

	// åˆ›å»ºç”Ÿäº§è€…é…ç½® - æŒ‰ç…§å®˜æ–¹ç¤ºä¾‹
	opts := []producer.Option{
		// ä½¿ç”¨å®˜æ–¹æ¨èçš„NameServeré…ç½®æ–¹å¼
		producer.WithNsResolver(primitive.NewPassthroughResolver([]string{req.Endpoint})),
		producer.WithCredentials(primitive.Credentials{
			AccessKey: req.AccessKeyId,
			SecretKey: req.AccessKeySecret,
		}),
		producer.WithGroupName(producerGroup),
		producer.WithRetry(2),
	}

	// åˆ›å»ºç”Ÿäº§è€…
	p, err := rocketmq.NewProducer(opts...)
	if err != nil {
		return &proto.CreateProducerResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to create producer: %v", err),
		}, nil
	}

	// å¯åŠ¨ç”Ÿäº§è€…
	err = p.Start()
	if err != nil {
		// å¯åŠ¨å¤±è´¥æ—¶æ¸…ç†å·²åˆ›å»ºçš„ç”Ÿäº§è€…èµ„æº
		if shutdownErr := p.Shutdown(); shutdownErr != nil {
			log.Printf("âš ï¸ Error shutting down failed producer during cleanup: %v", shutdownErr)
		}
		return &proto.CreateProducerResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to start producer: %v", err),
		}, nil
	}

	// ç”Ÿæˆå”¯ä¸€ID
	producerID := uuid.New().String()

	// å­˜å‚¨ç”Ÿäº§è€…ä¿¡æ¯
	s.producers[producerID] = &ProducerInfo{
		Producer:   p,
		Topic:      req.Topic,
		Endpoint:   req.Endpoint,
		InstanceId: req.InstanceId,
		RefCount:   1,
		LastActive: time.Now(),
		CreatedAt:  time.Now(),
	}

	// è®°å½•å¤ç”¨æ˜ å°„
	s.sharedProducers[connKey] = producerID

	// å¢åŠ ç”Ÿäº§è€…è®¡æ•°
	metrics.GlobalMetrics.IncActiveProducers()

	log.Printf("ğŸš€ New producer created: ID=%s, Group=%s, Topic=%s, Instance=%s",
		producerID, producerGroup, req.Topic, req.InstanceId)
	return &proto.CreateProducerResponse{
		Success:    true,
		Message:    "Producer created successfully",
		ProducerId: producerID,
	}, nil
}

// SendMessage å‘é€æ¶ˆæ¯
func (s *RocketMQProxyService) SendMessage(ctx context.Context, req *proto.SendMessageRequest) (*proto.SendMessageResponse, error) {
	log.Printf("Sending message with producer: %s", req.ProducerId)

	// è·å–ç”Ÿäº§è€…
	s.mu.RLock()
	producerInfo, exists := s.producers[req.ProducerId]
	s.mu.RUnlock()

	if !exists {
		return &proto.SendMessageResponse{
			Success: false,
			Message: "Producer not found",
		}, status.Error(codes.NotFound, "Producer not found")
	}

	// æ›´æ–°ç”Ÿäº§è€…æœ€åæ´»è·ƒæ—¶é—´
	s.mu.Lock()
	if info, ok := s.producers[req.ProducerId]; ok {
		info.LastActive = time.Now()
	}
	s.mu.Unlock()

	// æ„å»ºæ¶ˆæ¯
	msg := &primitive.Message{
		Topic: producerInfo.Topic,
		Body:  []byte(req.MessageBody),
	}

	// è®¾ç½®Tag
	if req.Tag != "" {
		msg.WithTag(req.Tag)
	}

	// å¤„ç†æ¶ˆæ¯å±æ€§
	if req.Properties != nil {
		// è®¾ç½®è‡ªå®šä¹‰å±æ€§
		for k, v := range req.Properties.Properties {
			msg.WithProperty(k, v)
		}

		// è®¾ç½®æ¶ˆæ¯Key
		if req.Properties.MessageKey != "" {
			msg.WithKeys([]string{req.Properties.MessageKey})
		}

		// è®¾ç½®åˆ†åŒºé”®(é¡ºåºæ¶ˆæ¯)
		if req.Properties.ShardingKey != "" {
			msg.WithShardingKey(req.Properties.ShardingKey)
		}

		// è®¾ç½®å»¶æ—¶æŠ•é€’æ—¶é—´ - æ”¯æŒå­—èŠ‚äº‘çš„ä»»æ„ç²¾åº¦å»¶æ—¶æ¶ˆæ¯
		if req.Properties.StartDeliverTime > 0 {
			// ä½¿ç”¨å­—èŠ‚äº‘çš„ __STARTDELIVERTIME å±æ€§å®ç°ä»»æ„ç²¾åº¦å»¶æ—¶
			msg.WithProperty("__STARTDELIVERTIME", fmt.Sprintf("%d", req.Properties.StartDeliverTime))
			log.Printf("Using arbitrary precision delay with __STARTDELIVERTIME: %d", req.Properties.StartDeliverTime)
		}
	}

	// å‘é€æ¶ˆæ¯
	result, err := producerInfo.Producer.SendSync(ctx, msg)
	if err != nil {
		metrics.GlobalMetrics.IncErrorCount()
		return &proto.SendMessageResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to send message: %v", err),
		}, nil
	}

	// å¢åŠ å‘é€æ¶ˆæ¯è®¡æ•°
	metrics.GlobalMetrics.IncMessagesSent()

	return &proto.SendMessageResponse{
		Success:       true,
		Message:       "Message sent successfully",
		MessageId:     result.MsgID,
		ReceiptHandle: result.MsgID,
	}, nil
}

// SendOrderedMessage å‘é€é¡ºåºæ¶ˆæ¯
func (s *RocketMQProxyService) SendOrderedMessage(ctx context.Context, req *proto.SendOrderedMessageRequest) (*proto.SendMessageResponse, error) {
	log.Printf("Sending ordered message with producer: %s, sharding key: %s", req.ProducerId, req.ShardingKey)

	// è·å–ç”Ÿäº§è€…
	s.mu.RLock()
	producerInfo, exists := s.producers[req.ProducerId]
	s.mu.RUnlock()

	if !exists {
		return &proto.SendMessageResponse{
			Success: false,
			Message: "Producer not found",
		}, status.Error(codes.NotFound, "Producer not found")
	}

	// æ„å»ºé¡ºåºæ¶ˆæ¯
	msg := &primitive.Message{
		Topic: producerInfo.Topic,
		Body:  []byte(req.MessageBody),
	}

	// è®¾ç½®Tag
	if req.Tag != "" {
		msg.WithTag(req.Tag)
	}

	// è®¾ç½®åˆ†åŒºé”®ï¼ˆé¡ºåºæ¶ˆæ¯çš„å…³é”®ï¼‰
	if req.ShardingKey != "" {
		msg.WithShardingKey(req.ShardingKey)
	}

	// å¤„ç†æ¶ˆæ¯å±æ€§
	if req.Properties != nil {
		for k, v := range req.Properties.Properties {
			msg.WithProperty(k, v)
		}
		if req.Properties.MessageKey != "" {
			msg.WithKeys([]string{req.Properties.MessageKey})
		}
	}

	// å‘é€é¡ºåºæ¶ˆæ¯
	result, err := producerInfo.Producer.SendSync(ctx, msg)
	if err != nil {
		metrics.GlobalMetrics.IncErrorCount()
		return &proto.SendMessageResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to send ordered message: %v", err),
		}, nil
	}

	metrics.GlobalMetrics.IncMessagesSent()
	log.Printf("âœ… Ordered message sent successfully: %s", result.MsgID)

	return &proto.SendMessageResponse{
		Success:       true,
		Message:       "Ordered message sent successfully",
		MessageId:     result.MsgID,
		ReceiptHandle: result.MsgID,
	}, nil
}

// SendDelayMessage å‘é€å»¶è¿Ÿæ¶ˆæ¯
func (s *RocketMQProxyService) SendDelayMessage(ctx context.Context, req *proto.SendDelayMessageRequest) (*proto.SendMessageResponse, error) {
	log.Printf("Sending delay message with producer: %s, delay level: %d, deliver time: %d",
		req.ProducerId, req.DelayTimeLevel, req.StartDeliverTime)

	// è·å–ç”Ÿäº§è€…
	s.mu.RLock()
	producerInfo, exists := s.producers[req.ProducerId]
	s.mu.RUnlock()

	if !exists {
		return &proto.SendMessageResponse{
			Success: false,
			Message: "Producer not found",
		}, status.Error(codes.NotFound, "Producer not found")
	}

	// æ„å»ºå»¶è¿Ÿæ¶ˆæ¯
	msg := &primitive.Message{
		Topic: producerInfo.Topic,
		Body:  []byte(req.MessageBody),
	}

	// è®¾ç½®Tag
	if req.Tag != "" {
		msg.WithTag(req.Tag)
	}

	// è®¾ç½®å»¶è¿Ÿæ—¶é—´ - æ”¯æŒå­—èŠ‚äº‘çš„ä»»æ„ç²¾åº¦å»¶æ—¶æ¶ˆæ¯
	if req.StartDeliverTime > 0 {
		// ä½¿ç”¨å­—èŠ‚äº‘çš„ __STARTDELIVERTIME å±æ€§å®ç°ä»»æ„ç²¾åº¦å»¶æ—¶
		msg.WithProperty("__STARTDELIVERTIME", fmt.Sprintf("%d", req.StartDeliverTime))
		log.Printf("Using arbitrary precision delay with __STARTDELIVERTIME: %d", req.StartDeliverTime)
	} else if req.DelayTimeLevel > 0 {
		// å…¼å®¹ä¼ ç»Ÿçš„å»¶è¿Ÿç­‰çº§ (1-18)ï¼Œä½¿ç”¨RocketMQåŸç”Ÿå»¶è¿Ÿç­‰çº§
		msg.WithDelayTimeLevel(int(req.DelayTimeLevel))
		log.Printf("Using traditional delay level: %d", req.DelayTimeLevel)
	}

	// å¤„ç†æ¶ˆæ¯å±æ€§
	if req.Properties != nil {
		for k, v := range req.Properties.Properties {
			msg.WithProperty(k, v)
		}
		if req.Properties.MessageKey != "" {
			msg.WithKeys([]string{req.Properties.MessageKey})
		}
	}

	// å‘é€å»¶è¿Ÿæ¶ˆæ¯
	result, err := producerInfo.Producer.SendSync(ctx, msg)
	if err != nil {
		metrics.GlobalMetrics.IncErrorCount()
		return &proto.SendMessageResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to send delay message: %v", err),
		}, nil
	}

	metrics.GlobalMetrics.IncMessagesSent()
	log.Printf("âœ… Delay message sent successfully: %s", result.MsgID)

	return &proto.SendMessageResponse{
		Success:       true,
		Message:       "Delay message sent successfully",
		MessageId:     result.MsgID,
		ReceiptHandle: result.MsgID,
	}, nil
}

// SendTransactionMessage å‘é€äº‹åŠ¡æ¶ˆæ¯
func (s *RocketMQProxyService) SendTransactionMessage(ctx context.Context, req *proto.SendTransactionMessageRequest) (*proto.SendTransactionMessageResponse, error) {
	log.Printf("Sending transaction message with producer: %s, immunity time: %d",
		req.ProducerId, req.TransCheckImmunityTime)

	// è·å–ç”Ÿäº§è€…
	s.mu.RLock()
	producerInfo, exists := s.producers[req.ProducerId]
	s.mu.RUnlock()

	if !exists {
		return &proto.SendTransactionMessageResponse{
			Success: false,
			Message: "Producer not found",
		}, status.Error(codes.NotFound, "Producer not found")
	}

	// æ„å»ºäº‹åŠ¡æ¶ˆæ¯
	msg := &primitive.Message{
		Topic: producerInfo.Topic,
		Body:  []byte(req.MessageBody),
	}

	// è®¾ç½®Tag
	if req.Tag != "" {
		msg.WithTag(req.Tag)
	}

	// è®¾ç½®äº‹åŠ¡å›æŸ¥å…ç–«æ—¶é—´
	if req.TransCheckImmunityTime > 0 {
		// RocketMQ Go SDKä¸­äº‹åŠ¡æ¶ˆæ¯çš„å¤„ç†æ–¹å¼
		msg.WithProperty("__STARTDELIVERTIME", fmt.Sprintf("%d", time.Now().Add(time.Duration(req.TransCheckImmunityTime)*time.Second).UnixMilli()))
	}

	// å¤„ç†æ¶ˆæ¯å±æ€§
	if req.Properties != nil {
		for k, v := range req.Properties.Properties {
			msg.WithProperty(k, v)
		}
		if req.Properties.MessageKey != "" {
			msg.WithKeys([]string{req.Properties.MessageKey})
		}
	}

	// å‘é€äº‹åŠ¡æ¶ˆæ¯ï¼ˆè¿™é‡Œä½¿ç”¨æ™®é€šå‘é€ï¼Œå®é™…äº‹åŠ¡é€»è¾‘éœ€è¦æ›´å¤æ‚çš„å¤„ç†ï¼‰
	result, err := producerInfo.Producer.SendSync(ctx, msg)
	if err != nil {
		metrics.GlobalMetrics.IncErrorCount()
		return &proto.SendTransactionMessageResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to send transaction message: %v", err),
		}, nil
	}

	metrics.GlobalMetrics.IncMessagesSent()
	log.Printf("âœ… Transaction message sent successfully: %s", result.MsgID)

	return &proto.SendTransactionMessageResponse{
		Success:       true,
		Message:       "Transaction message sent successfully",
		MessageId:     result.MsgID,
		ReceiptHandle: result.MsgID,
		TransactionId: fmt.Sprintf("trans_%s_%d", result.MsgID, time.Now().UnixNano()),
	}, nil
}

// CreateConsumer åˆ›å»ºæ¶ˆè´¹è€… - æ”¯æŒé›†ç¾¤æ¶ˆè´¹æ¨¡å¼å’Œæ¶ˆè´¹è€…å¤ç”¨ï¼Œæ”¯æŒåŒä¸€GroupIDè®¢é˜…å¤šä¸ªTopic
func (s *RocketMQProxyService) CreateConsumer(ctx context.Context, req *proto.CreateConsumerRequest) (*proto.CreateConsumerResponse, error) {
	log.Printf("Creating consumer for topic: %s, group: %s (cluster mode with consumer reuse)", req.Topic, req.GroupId)

	// ç”Ÿæˆæ¶ˆè´¹è€…è¿æ¥keyï¼ŒæŒ‰GroupID+Endpointå¤ç”¨ï¼Œæ”¯æŒå¤šTopicè®¢é˜…å’Œä¸åŒRocketMQå®ä¾‹
	consumerKey := ConsumerKey{
		Endpoint:    req.Endpoint,
		AccessKeyId: req.AccessKeyId,
		InstanceId:  req.InstanceId,
		GroupID:     req.GroupId,
	}

	s.mu.Lock()
	defer s.mu.Unlock()

	// æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒGroupIDçš„æ¶ˆè´¹è€…å¯ä»¥å¤ç”¨
	if existingConsumerID, exists := s.sharedConsumers[consumerKey]; exists {
		if consumerInfo, found := s.consumers[existingConsumerID]; found {
			// æ£€æŸ¥ç°æœ‰æ¶ˆè´¹è€…æ˜¯å¦è¿˜æ´»è·ƒ
			timeSinceLastActive := time.Since(consumerInfo.LastActive)

			if timeSinceLastActive < 5*time.Minute {
				// æ£€æŸ¥æ˜¯å¦å·²ç»è®¢é˜…äº†è¿™ä¸ªTopic
				if !consumerInfo.Topics[req.Topic] {
					// ä¸ºç°æœ‰æ¶ˆè´¹è€…æ·»åŠ æ–°Topicè®¢é˜…
					selector := consumer.MessageSelector{
						Type:       consumer.TAG,
						Expression: req.TagExpression,
					}

					err := consumerInfo.Consumer.Subscribe(req.Topic, selector, func(ctx context.Context, msgs ...*primitive.MessageExt) (consumer.ConsumeResult, error) {
						select {
						case <-ctx.Done():
							return consumer.ConsumeRetryLater, fmt.Errorf("consumer context cancelled")
						default:
						}

						for _, msg := range msgs {
							metrics.GlobalMetrics.IncMessagesReceived()

							protoMsg := &proto.Message{
								MessageId:      msg.MsgId,
								ReceiptHandle:  msg.MsgId,
								MessageBody:    string(msg.Body),
								Tag:            msg.GetTags(),
								Properties:     msg.GetProperties(),
								BornTimestamp:  msg.BornTimestamp,
								ReconsumeTimes: int32(msg.ReconsumeTimes),
							}

							select {
							case consumerInfo.MessageChan <- protoMsg:
								log.Printf("Message sent to channel: %s (topic: %s)", msg.MsgId, msg.Topic)
							case <-time.After(5 * time.Second):
								log.Printf("âš ï¸ Message channel send timeout, will retry later: %s", msg.MsgId)
								metrics.GlobalMetrics.IncChannelFullEvents()
								return consumer.ConsumeRetryLater, fmt.Errorf("message channel timeout - will retry")
							}
						}
						return consumer.ConsumeSuccess, nil
					})

					if err != nil {
						log.Printf("âš ï¸ Failed to add topic subscription %s to existing consumer: %v", req.Topic, err)
						// å¦‚æœæ·»åŠ è®¢é˜…å¤±è´¥ï¼Œç»§ç»­åˆ›å»ºæ–°çš„æ¶ˆè´¹è€…
					} else {
						// æˆåŠŸæ·»åŠ Topicè®¢é˜…
						consumerInfo.Topics[req.Topic] = true
						log.Printf("âœ… Added topic %s to existing consumer group %s", req.Topic, req.GroupId)
					}
				}

				// æ¶ˆè´¹è€…ä»ç„¶æ´»è·ƒï¼Œå¤ç”¨ç°æœ‰æ¶ˆè´¹è€…
				newConsumerID := uuid.New().String()

				// ç›´æ¥å¼•ç”¨åŒä¸€ä¸ªConsumerInfoå®ä¾‹ï¼Œè€Œä¸æ˜¯åˆ›å»ºæ–°çš„
				s.consumers[newConsumerID] = consumerInfo
				consumerInfo.RefCount++
				consumerInfo.LastActive = time.Now()

				topicList := make([]string, 0, len(consumerInfo.Topics))
				for topic := range consumerInfo.Topics {
					topicList = append(topicList, topic)
				}

				log.Printf("âœ… Reusing consumer: ID=%s, Group=%s, Topics=%v, RefCount=%d",
					newConsumerID, req.GroupId, topicList, consumerInfo.RefCount)
				return &proto.CreateConsumerResponse{
					Success:    true,
					Message:    fmt.Sprintf("Consumer reused (ref: %d) - cluster mode, topics: %v", consumerInfo.RefCount, topicList),
					ConsumerId: newConsumerID,
				}, nil
			} else {
				// æ¶ˆè´¹è€…ä¸æ´»è·ƒï¼Œæ¸…ç†åé‡æ–°åˆ›å»º
				log.Printf("ğŸ”„ Found inactive shared consumer, will recreate: %s (inactive for %v)", existingConsumerID, timeSinceLastActive)
				s.cleanupSharedConsumerInternal(consumerKey, existingConsumerID)
			}
		}
	}

	// æ¸…ç†å…¶ä»–ä¸æ´»è·ƒçš„æ¶ˆè´¹è€…ï¼ˆä½†ä¸å½±å“å½“å‰åˆ›å»ºï¼‰
	var inactiveConsumers []string
	for consumerID, existingConsumer := range s.consumers {
		if existingConsumer.GroupID == req.GroupId {
			timeSinceLastActive := time.Since(existingConsumer.LastActive)
			if timeSinceLastActive > 5*time.Minute {
				inactiveConsumers = append(inactiveConsumers, consumerID)
				log.Printf("ğŸ”„ Found long-inactive consumer, will clean up: %s (inactive for %v)", consumerID, timeSinceLastActive)
			}
		}
	}

	// é‡Šæ”¾é”åæ¸…ç†ä¸æ´»è·ƒçš„æ¶ˆè´¹è€…
	s.mu.Unlock()
	for _, consumerID := range inactiveConsumers {
		if err := s.CleanupConsumerByID(consumerID); err != nil {
			log.Printf("âš ï¸ Error cleaning up inactive consumer: %v", err)
		}
	}
	s.mu.Lock()

	// åˆ›å»ºæ–°çš„æ¶ˆè´¹è€…
	consumerGroup := req.GroupId

	// åˆ›å»ºå¸¦å–æ¶ˆåŠŸèƒ½çš„ä¸Šä¸‹æ–‡
	consumerCtx, cancelFunc := context.WithCancel(context.Background())

	// åˆ›å»ºæ¶ˆè´¹è€…é…ç½® - æ˜ç¡®å¯ç”¨é›†ç¾¤æ¶ˆè´¹æ¨¡å¼
	opts := []consumer.Option{
		consumer.WithNsResolver(primitive.NewPassthroughResolver([]string{req.Endpoint})),
		consumer.WithCredentials(primitive.Credentials{
			AccessKey: req.AccessKeyId,
			SecretKey: req.AccessKeySecret,
		}),
		consumer.WithGroupName(consumerGroup),
		consumer.WithConsumeFromWhere(consumer.ConsumeFromLastOffset),
		consumer.WithConsumerModel(consumer.Clustering),
		consumer.WithConsumerPullTimeout(s.config.PullTimeout),
		consumer.WithPullInterval(s.config.PullInterval),
		consumer.WithMaxReconsumeTimes(3),
		consumer.WithConsumeMessageBatchMaxSize(32),
	}

	// åˆ›å»ºæ¶ˆè´¹è€…
	c, err := rocketmq.NewPushConsumer(opts...)
	if err != nil {
		cancelFunc()
		return &proto.CreateConsumerResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to create consumer: %v", err),
		}, nil
	}

	// ç”Ÿæˆå”¯ä¸€ID
	consumerID := uuid.New().String()

	// åˆ›å»ºæ¶ˆæ¯é€šé“
	messageChan := make(chan *proto.Message, s.config.MessageBufferSize)

	// è®¢é˜…ä¸»é¢˜
	selector := consumer.MessageSelector{
		Type:       consumer.TAG,
		Expression: req.TagExpression,
	}

	err = c.Subscribe(req.Topic, selector, func(ctx context.Context, msgs ...*primitive.MessageExt) (consumer.ConsumeResult, error) {
		select {
		case <-consumerCtx.Done():
			return consumer.ConsumeRetryLater, fmt.Errorf("consumer context cancelled")
		default:
		}

		for _, msg := range msgs {
			metrics.GlobalMetrics.IncMessagesReceived()

			protoMsg := &proto.Message{
				MessageId:      msg.MsgId,
				ReceiptHandle:  msg.MsgId,
				MessageBody:    string(msg.Body),
				Tag:            msg.GetTags(),
				Properties:     msg.GetProperties(),
				BornTimestamp:  msg.BornTimestamp,
				ReconsumeTimes: int32(msg.ReconsumeTimes),
			}

			select {
			case messageChan <- protoMsg:
				log.Printf("Message sent to channel: %s (topic: %s)", msg.MsgId, msg.Topic)
			case <-consumerCtx.Done():
				log.Printf("Consumer context cancelled, dropping message: %s", msg.MsgId)
				return consumer.ConsumeRetryLater, fmt.Errorf("consumer context cancelled")
			case <-time.After(5 * time.Second):
				log.Printf("âš ï¸ Message channel send timeout, will retry later: %s", msg.MsgId)
				metrics.GlobalMetrics.IncChannelFullEvents()
				return consumer.ConsumeRetryLater, fmt.Errorf("message channel timeout - will retry")
			}
		}
		return consumer.ConsumeSuccess, nil
	})

	if err != nil {
		cancelFunc()
		return &proto.CreateConsumerResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to subscribe topic: %v", err),
		}, nil
	}

	// å¯åŠ¨æ¶ˆè´¹è€…
	err = c.Start()
	if err != nil {
		cancelFunc()
		return &proto.CreateConsumerResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to start consumer: %v", err),
		}, nil
	}

	// å­˜å‚¨æ¶ˆè´¹è€…ä¿¡æ¯
	consumerInfo := &ConsumerInfo{
		Consumer:    c,
		Topics:      map[string]bool{req.Topic: true}, // åˆå§‹åŒ–Topicsæ˜ å°„
		GroupID:     consumerGroup,
		Endpoint:    req.Endpoint,
		InstanceId:  req.InstanceId,
		MessageChan: messageChan,
		CancelFunc:  cancelFunc,
		LastActive:  time.Now(),
		RefCount:    1,
		CreatedAt:   time.Now(),
	}

	s.consumers[consumerID] = consumerInfo

	// è®°å½•å¤ç”¨æ˜ å°„
	s.sharedConsumers[consumerKey] = consumerID

	// ç»Ÿè®¡åŒç»„æ¶ˆè´¹è€…æ•°é‡
	sameGroupCount := 0
	for _, consumer := range s.consumers {
		if consumer.GroupID == consumerGroup {
			sameGroupCount++
		}
	}

	// å¢åŠ æ¶ˆè´¹è€…è®¡æ•°
	metrics.GlobalMetrics.IncActiveConsumers()

	log.Printf("âœ… New consumer created: ID=%s, Group=%s, Topic=%s (cluster mode: %d consumers in group)",
		consumerID, consumerGroup, req.Topic, sameGroupCount)
	return &proto.CreateConsumerResponse{
		Success:    true,
		Message:    fmt.Sprintf("Consumer created successfully for group: %s (cluster mode: %d consumers)", consumerGroup, sameGroupCount),
		ConsumerId: consumerID,
	}, nil
}

// ReceiveMessages æ¥æ”¶æ¶ˆæ¯(æµå¼)
func (s *RocketMQProxyService) ReceiveMessages(req *proto.ReceiveMessagesRequest, stream proto.RocketMQProxy_ReceiveMessagesServer) error {
	log.Printf("ğŸ¬ Starting message stream for consumer: %s", req.ConsumerId)

	// è·å–æ¶ˆè´¹è€…
	s.mu.RLock()
	consumerInfo, exists := s.consumers[req.ConsumerId]
	s.mu.RUnlock()

	if !exists {
		return status.Error(codes.NotFound, "Consumer not found")
	}

	// æ›´æ–°æœ€åæ´»è·ƒæ—¶é—´
	s.mu.Lock()
	if info, ok := s.consumers[req.ConsumerId]; ok {
		info.LastActive = time.Now()
	}
	s.mu.Unlock()

	// åˆ›å»ºå—æ§çš„ä¸Šä¸‹æ–‡
	ctx, cancel := context.WithCancel(stream.Context())
	defer cancel()

	// ç¼©çŸ­å¿ƒè·³é—´éš”ï¼Œæ›´å¿«æ£€æµ‹æ–­å¼€è¿æ¥
	heartbeatTicker := time.NewTicker(10 * time.Second)
	defer heartbeatTicker.Stop()

	// StreamçŠ¶æ€ç›‘æ§ - ä½¿ç”¨å—æ§çš„goroutine
	streamDone := make(chan bool, 1)
	go func() {
		defer func() {
			if r := recover(); r != nil {
				log.Printf("âš ï¸ Stream monitor goroutine recovered from panic: %v", r)
			}
		}()
		select {
		case <-ctx.Done():
			return
		case <-stream.Context().Done():
			select {
			case streamDone <- true:
			default:
			}
			return
		}
	}()

	// ç¡®ä¿åœ¨å‡½æ•°é€€å‡ºæ—¶æ¸…ç†æ¶ˆè´¹è€… - ç›´æ¥è°ƒç”¨ï¼Œä¸ä½¿ç”¨é¢å¤–goroutine
	defer func() {
		log.Printf("ğŸ”š Stream ended for consumer: %s, reason: client disconnection", req.ConsumerId)

		// ç›´æ¥æ¸…ç†ï¼Œé¿å…goroutineæ³„æ¼
		if err := s.CleanupConsumerByID(req.ConsumerId); err != nil {
			log.Printf("âŒ Error cleaning up consumer %s: %v", req.ConsumerId, err)
		} else {
			log.Printf("âœ… Consumer %s cleaned up immediately after stream end", req.ConsumerId)
		}
	}()

	log.Printf("ğŸ“¡ Consumer %s ready to receive messages (heartbeat: 10s)", req.ConsumerId)

	// ä»æ¶ˆæ¯é€šé“è¯»å–å¹¶å‘é€æ¶ˆæ¯
	for {
		select {
		case <-streamDone:
			log.Printf("ğŸ“´ Client disconnected for consumer: %s", req.ConsumerId)
			return nil

		case <-ctx.Done():
			log.Printf("ğŸ“´ Stream context done for consumer: %s", req.ConsumerId)
			return nil

		case msg, ok := <-consumerInfo.MessageChan:
			if !ok {
				// é€šé“å·²å…³é—­
				log.Printf("ğŸ“¨ Message channel closed for consumer: %s", req.ConsumerId)
				return nil
			}

			if err := stream.Send(msg); err != nil {
				log.Printf("âŒ Failed to send message to stream for consumer %s: %v", req.ConsumerId, err)
				return err
			}

			// æ›´æ–°æœ€åæ´»è·ƒæ—¶é—´
			s.mu.Lock()
			if info, ok := s.consumers[req.ConsumerId]; ok {
				info.LastActive = time.Now()
			}
			s.mu.Unlock()

		case <-heartbeatTicker.C:
			// å‘é€å¿ƒè·³ï¼Œæ›´æ–°æ´»è·ƒæ—¶é—´
			s.mu.Lock()
			if info, ok := s.consumers[req.ConsumerId]; ok {
				info.LastActive = time.Now()
				log.Printf("ğŸ’“ Heartbeat for consumer: %s (group: %s)", req.ConsumerId, info.GroupID)
			}
			s.mu.Unlock()
		}
	}
}

// AckMessage ç¡®è®¤æ¶ˆæ¯
func (s *RocketMQProxyService) AckMessage(ctx context.Context, req *proto.AckMessageRequest) (*proto.AckMessageResponse, error) {
	log.Printf("Acking message for consumer: %s", req.ConsumerId)

	// åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œåº”è¯¥ç¡®è®¤å…·ä½“çš„æ¶ˆæ¯
	// RocketMQçš„ç¡®è®¤æ˜¯åœ¨æ¶ˆè´¹å›è°ƒä¸­å¤„ç†çš„ï¼Œè¿™é‡Œå¯ä»¥è®°å½•ç¡®è®¤çŠ¶æ€

	return &proto.AckMessageResponse{
		Success: true,
		Message: "Message acknowledged",
	}, nil
}

// CleanupProducer æ¸…ç†ç”Ÿäº§è€… (gRPC API)
func (s *RocketMQProxyService) CleanupProducer(ctx context.Context, req *proto.CleanupProducerRequest) (*proto.CleanupProducerResponse, error) {
	log.Printf("ğŸ§¹ Manual producer cleanup request - ProducerID: %s, Topic: %s, Endpoint: %s", req.ProducerId, req.Topic, req.Endpoint)

	cleanedCount := int32(0)
	var cleanupErrors []string

	s.mu.Lock()
	var toCleanup []string

	if req.ProducerId != "" {
		// é€šè¿‡ç”Ÿäº§è€…IDæ¸…ç†
		if _, exists := s.producers[req.ProducerId]; exists {
			toCleanup = append(toCleanup, req.ProducerId)
		}
	} else if req.Topic != "" {
		// é€šè¿‡ä¸»é¢˜æ¸…ç†ï¼ˆå¯é€‰é…åˆEndpointï¼‰
		for producerID, producerInfo := range s.producers {
			if producerInfo.Topic == req.Topic {
				if req.Endpoint == "" || producerInfo.Endpoint == req.Endpoint {
					toCleanup = append(toCleanup, producerID)
				}
			}
		}
	}
	s.mu.Unlock()

	// æ‰§è¡Œæ¸…ç†
	for _, producerID := range toCleanup {
		if err := s.cleanupProducerInternal(producerID); err != nil {
			cleanupErrors = append(cleanupErrors, fmt.Sprintf("Producer %s: %v", producerID, err))
		} else {
			cleanedCount++
			log.Printf("âœ… Manually cleaned up producer: %s", producerID)
		}
	}

	// æ„å»ºå“åº”æ¶ˆæ¯
	var message string
	success := len(cleanupErrors) == 0

	if cleanedCount > 0 {
		message = fmt.Sprintf("Successfully cleaned up %d producer(s)", cleanedCount)
		if len(cleanupErrors) > 0 {
			message += fmt.Sprintf(", but %d failed: %v", len(cleanupErrors), cleanupErrors)
		}
	} else {
		if req.ProducerId != "" {
			message = "No producer found with the specified ID"
		} else {
			message = "No producers found matching the criteria"
		}
	}

	return &proto.CleanupProducerResponse{
		Success:      success,
		Message:      message,
		CleanedCount: cleanedCount,
	}, nil
}

// cleanupProducerInternal å†…éƒ¨ç”Ÿäº§è€…æ¸…ç†æ–¹æ³•
func (s *RocketMQProxyService) cleanupProducerInternal(producerID string) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	producerInfo, exists := s.producers[producerID]
	if !exists {
		return fmt.Errorf("producer not found: %s", producerID)
	}

	log.Printf("ğŸ§¹ Cleaning up producer: ID=%s, Topic=%s, Endpoint=%s, RefCount=%d",
		producerID, producerInfo.Topic, producerInfo.Endpoint, producerInfo.RefCount)

	// å‡å°‘å¼•ç”¨è®¡æ•°
	producerInfo.RefCount--

	// å¦‚æœå¼•ç”¨è®¡æ•°å¤§äº0ï¼Œåªæ˜¯ç§»é™¤å½“å‰IDï¼Œä½†ä¿æŒç”Ÿäº§è€…å®ä¾‹
	if producerInfo.RefCount > 0 {
		delete(s.producers, producerID)
		log.Printf("âœ… Producer instance preserved with RefCount=%d", producerInfo.RefCount)
		return nil
	}

	// å¼•ç”¨è®¡æ•°ä¸º0ï¼ŒçœŸæ­£æ¸…ç†èµ„æº
	if err := producerInfo.Producer.Shutdown(); err != nil {
		log.Printf("âš ï¸ Error shutting down producer %s: %v", producerID, err)
	}

	// ä»æ˜ å°„ä¸­åˆ é™¤
	delete(s.producers, producerID)

	// æ¸…ç†å…±äº«æ˜ å°„ - åˆ é™¤æ‰€æœ‰æŒ‡å‘è¯¥producerIDçš„æ˜ å°„
	keysToDelete := make([]ConnectionKey, 0)
	for key, id := range s.sharedProducers {
		if id == producerID {
			keysToDelete = append(keysToDelete, key)
		}
	}
	for _, key := range keysToDelete {
		delete(s.sharedProducers, key)
	}

	// å‡å°‘ç”Ÿäº§è€…è®¡æ•°
	metrics.GlobalMetrics.DecActiveProducers()

	log.Printf("âœ… Producer cleanup completed: %s", producerID)
	return nil
}

// CleanupInactiveProducers æ¸…ç†ä¸æ´»è·ƒçš„ç”Ÿäº§è€…ï¼ˆå®šæ—¶ä»»åŠ¡ï¼‰
func (s *RocketMQProxyService) CleanupInactiveProducers(timeout time.Duration) {
	var toCleanup []string

	// åªåœ¨è¯»å–æ—¶è·å–é”
	func() {
		s.mu.RLock()
		defer s.mu.RUnlock()

		now := time.Now()
		for producerID, producerInfo := range s.producers {
			if now.Sub(producerInfo.LastActive) > timeout {
				toCleanup = append(toCleanup, producerID)
			}
		}
	}()

	// é‡Šæ”¾é”åæ¸…ç†
	for _, producerID := range toCleanup {
		log.Printf("ğŸ•’ Cleaning up inactive producer: %s", producerID)
		if err := s.cleanupProducerInternal(producerID); err != nil {
			log.Printf("âŒ Error cleaning up inactive producer %s: %v", producerID, err)
		}
	}
}

// CleanupConsumerByID æ¸…ç†æŒ‡å®šçš„æ¶ˆè´¹è€…ï¼ˆå¤–éƒ¨è°ƒç”¨ï¼ŒåŒ…å«é”ç®¡ç†ï¼‰
func (s *RocketMQProxyService) CleanupConsumerByID(consumerID string) error {
	return s.cleanupConsumerInternal(consumerID)
}

// cleanupConsumerInternal å†…éƒ¨æ¸…ç†æ–¹æ³•ï¼ˆæ”¯æŒå¼•ç”¨è®¡æ•°ï¼‰
func (s *RocketMQProxyService) cleanupConsumerInternal(consumerID string) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	consumerInfo, exists := s.consumers[consumerID]
	if !exists {
		return fmt.Errorf("consumer not found: %s", consumerID)
	}

	log.Printf("ğŸ§¹ Cleaning up consumer: ID=%s, Group=%s, Topics=%v, RefCount=%d",
		consumerID, consumerInfo.GroupID, getTopicList(consumerInfo.Topics), consumerInfo.RefCount)

	// å‡å°‘å¼•ç”¨è®¡æ•°
	consumerInfo.RefCount--

	// å¦‚æœå¼•ç”¨è®¡æ•°å¤§äº0ï¼Œåªæ˜¯ç§»é™¤å½“å‰IDï¼Œä½†ä¿æŒæ¶ˆè´¹è€…å®ä¾‹
	if consumerInfo.RefCount > 0 {
		delete(s.consumers, consumerID)
		log.Printf("âœ… Consumer instance preserved with RefCount=%d", consumerInfo.RefCount)
		return nil
	}

	// å¼•ç”¨è®¡æ•°ä¸º0ï¼ŒçœŸæ­£æ¸…ç†èµ„æº
	// å–æ¶ˆæ¶ˆè´¹è€…ä¸Šä¸‹æ–‡
	if consumerInfo.CancelFunc != nil {
		consumerInfo.CancelFunc()
	}

	// åœæ­¢æ¶ˆè´¹è€…
	if err := consumerInfo.Consumer.Shutdown(); err != nil {
		log.Printf("âš ï¸ Error shutting down consumer %s: %v", consumerID, err)
	}

	// å…³é—­æ¶ˆæ¯é€šé“
	if consumerInfo.MessageChan != nil {
		close(consumerInfo.MessageChan)
	}

	// æ‰¾åˆ°æ‰€æœ‰æŒ‡å‘åŒä¸€ä¸ªConsumerInfoå®ä¾‹çš„IDå¹¶æ¸…ç†
	var idsToDelete []string
	for id, info := range s.consumers {
		if info == consumerInfo {
			idsToDelete = append(idsToDelete, id)
		}
	}

	// åˆ é™¤æ‰€æœ‰ç›¸å…³çš„æ¶ˆè´¹è€…ID
	for _, id := range idsToDelete {
		delete(s.consumers, id)
		log.Printf("ğŸ§¹ Removed consumer ID: %s", id)
	}

	// æ¸…ç†å…±äº«æ˜ å°„ - åˆ é™¤æ‰€æœ‰æŒ‡å‘è¯¥consumerIDçš„æ˜ å°„
	keysToDelete := make([]ConsumerKey, 0)
	for key, id := range s.sharedConsumers {
		if id == consumerID {
			keysToDelete = append(keysToDelete, key)
		}
	}
	for _, key := range keysToDelete {
		delete(s.sharedConsumers, key)
	}

	// å‡å°‘æ¶ˆè´¹è€…è®¡æ•°
	metrics.GlobalMetrics.DecActiveConsumers()

	log.Printf("âœ… Consumer cleanup completed: %s (cleaned %d IDs)", consumerID, len(idsToDelete))
	return nil
}

// CleanupInactiveConsumers æ¸…ç†ä¸æ´»è·ƒçš„æ¶ˆè´¹è€…ï¼ˆå®šæ—¶ä»»åŠ¡ï¼‰
func (s *RocketMQProxyService) CleanupInactiveConsumers(timeout time.Duration) {
	var toCleanup []string

	// åªåœ¨è¯»å–æ—¶è·å–é”ï¼Œé¿å…åŒé‡è§£é”é—®é¢˜
	func() {
		s.mu.RLock()
		defer s.mu.RUnlock()

		now := time.Now()
		for consumerID, consumerInfo := range s.consumers {
			if now.Sub(consumerInfo.LastActive) > timeout {
				toCleanup = append(toCleanup, consumerID)
			}
		}
	}()

	// é‡Šæ”¾é”åæ¸…ç†
	for _, consumerID := range toCleanup {
		log.Printf("ğŸ•’ Cleaning up inactive consumer: %s", consumerID)
		if err := s.CleanupConsumerByID(consumerID); err != nil {
			log.Printf("âŒ Error cleaning up inactive consumer %s: %v", consumerID, err)
		}
	}
}

// CleanupConsumer æ¸…ç†æ¶ˆè´¹è€… (gRPC API)
func (s *RocketMQProxyService) CleanupConsumer(ctx context.Context, req *proto.CleanupConsumerRequest) (*proto.CleanupConsumerResponse, error) {
	log.Printf("ğŸ§¹ Manual cleanup request - ConsumerID: %s, GroupID: %s, Topic: %s", req.ConsumerId, req.GroupId, req.Topic)

	cleanedCount := int32(0)
	var cleanupErrors []string

	s.mu.Lock()
	var toCleanup []string

	if req.ConsumerId != "" {
		// é€šè¿‡æ¶ˆè´¹è€…IDæ¸…ç†
		if _, exists := s.consumers[req.ConsumerId]; exists {
			toCleanup = append(toCleanup, req.ConsumerId)
		}
	} else if req.GroupId != "" {
		// é€šè¿‡ç»„åæ¸…ç†ï¼ˆå¯é€‰é…åˆTopicï¼‰
		for consumerID, consumerInfo := range s.consumers {
			if consumerInfo.GroupID == req.GroupId {
				if req.Topic == "" || consumerInfo.Topics[req.Topic] {
					toCleanup = append(toCleanup, consumerID)
				}
			}
		}
	}
	s.mu.Unlock()

	// æ‰§è¡Œæ¸…ç†
	for _, consumerID := range toCleanup {
		if err := s.cleanupConsumerInternal(consumerID); err != nil {
			cleanupErrors = append(cleanupErrors, fmt.Sprintf("Consumer %s: %v", consumerID, err))
		} else {
			cleanedCount++
			log.Printf("âœ… Manually cleaned up consumer: %s", consumerID)
		}
	}

	// æ„å»ºå“åº”æ¶ˆæ¯
	var message string
	success := len(cleanupErrors) == 0

	if cleanedCount > 0 {
		message = fmt.Sprintf("Successfully cleaned up %d consumer(s)", cleanedCount)
		if len(cleanupErrors) > 0 {
			message += fmt.Sprintf(", but %d failed: %v", len(cleanupErrors), cleanupErrors)
		}
	} else {
		if req.ConsumerId != "" {
			message = "No consumer found with the specified ID"
		} else {
			message = "No consumers found matching the criteria"
		}
	}

	return &proto.CleanupConsumerResponse{
		Success:      success,
		Message:      message,
		CleanedCount: cleanedCount,
	}, nil
}

// HealthCheck å¥åº·æ£€æŸ¥
func (s *RocketMQProxyService) HealthCheck(ctx context.Context, req *proto.HealthCheckRequest) (*proto.HealthCheckResponse, error) {
	return &proto.HealthCheckResponse{
		Healthy: true,
		Message: "Service is healthy",
	}, nil
}

// calculateDelayLevel è®¡ç®—å»¶æ—¶ç­‰çº§ï¼ˆä»…ç”¨äºå…¼å®¹æ€§åœºæ™¯ï¼‰
// æ³¨æ„ï¼šå­—èŠ‚äº‘æ”¯æŒä»»æ„ç²¾åº¦å»¶æ—¶ï¼Œä¼˜å…ˆä½¿ç”¨ __STARTDELIVERTIME å±æ€§
func calculateDelayLevel(deliverTime int64) int {
	now := time.Now().UnixMilli()
	delay := deliverTime - now

	// RocketMQå»¶æ—¶ç­‰çº§: 1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h
	delayLevels := []int64{
		1000, 5000, 10000, 30000, 60000, 120000, 180000, 240000,
		300000, 360000, 420000, 480000, 540000, 600000, 1200000,
		1800000, 3600000, 7200000,
	}

	for i, level := range delayLevels {
		if delay <= level {
			return i + 1
		}
	}

	return 18 // æœ€å¤§å»¶æ—¶ç­‰çº§
}

// ShutdownAllProducers ä¼˜é›…å…³é—­æ‰€æœ‰ç”Ÿäº§è€… - ç”¨äºæœåŠ¡åœæ­¢æ—¶
func (s *RocketMQProxyService) ShutdownAllProducers() {
	s.mu.Lock()
	defer s.mu.Unlock()

	log.Printf("ğŸ›‘ Shutting down all producers...")

	// è®°å½•å”¯ä¸€çš„ç”Ÿäº§è€…å®ä¾‹ï¼Œé¿å…é‡å¤å…³é—­
	shutdownProducers := make(map[rocketmq.Producer]bool)

	for producerID, producerInfo := range s.producers {
		if !shutdownProducers[producerInfo.Producer] {
			log.Printf("ğŸ§¹ Shutting down producer: ID=%s, Topic=%s, RefCount=%d",
				producerID, producerInfo.Topic, producerInfo.RefCount)

			if err := producerInfo.Producer.Shutdown(); err != nil {
				log.Printf("âš ï¸ Error shutting down producer %s: %v", producerID, err)
			}
			shutdownProducers[producerInfo.Producer] = true
		}
	}

	// æ¸…ç©ºæ‰€æœ‰æ˜ å°„
	s.producers = make(map[string]*ProducerInfo)
	s.sharedProducers = make(map[ConnectionKey]string)

	// é‡ç½®è®¡æ•°å™¨
	metrics.GlobalMetrics.ResetActiveProducers()

	log.Printf("âœ… All producers shutdown completed")
}

// ShutdownAllConsumers ä¼˜é›…å…³é—­æ‰€æœ‰æ¶ˆè´¹è€… - ç”¨äºæœåŠ¡åœæ­¢æ—¶
func (s *RocketMQProxyService) ShutdownAllConsumers() {
	s.mu.Lock()
	defer s.mu.Unlock()

	log.Printf("ğŸ›‘ Shutting down all consumers...")

	// è®°å½•å”¯ä¸€çš„æ¶ˆè´¹è€…å®ä¾‹ï¼Œé¿å…é‡å¤å…³é—­
	shutdownConsumers := make(map[rocketmq.PushConsumer]bool)

	for consumerID, consumerInfo := range s.consumers {
		if !shutdownConsumers[consumerInfo.Consumer] {
			log.Printf("ğŸ§¹ Shutting down consumer: ID=%s, Group=%s, Topics=%v, RefCount=%d",
				consumerID, consumerInfo.GroupID, getTopicList(consumerInfo.Topics), consumerInfo.RefCount)

			// å–æ¶ˆæ¶ˆè´¹è€…ä¸Šä¸‹æ–‡
			if consumerInfo.CancelFunc != nil {
				consumerInfo.CancelFunc()
			}

			// åœæ­¢æ¶ˆè´¹è€…
			if err := consumerInfo.Consumer.Shutdown(); err != nil {
				log.Printf("âš ï¸ Error shutting down consumer %s: %v", consumerID, err)
			}

			// å…³é—­æ¶ˆæ¯é€šé“
			if consumerInfo.MessageChan != nil {
				close(consumerInfo.MessageChan)
			}

			shutdownConsumers[consumerInfo.Consumer] = true
		}
	}

	// æ¸…ç©ºæ‰€æœ‰æ˜ å°„
	s.consumers = make(map[string]*ConsumerInfo)
	s.sharedConsumers = make(map[ConsumerKey]string)

	// é‡ç½®è®¡æ•°å™¨
	metrics.GlobalMetrics.ResetActiveConsumers()

	log.Printf("âœ… All consumers shutdown completed")
}

// ValidateAndFixProducerRefCounts éªŒè¯å¹¶ä¿®å¤ç”Ÿäº§è€…å¼•ç”¨è®¡æ•°ä¸ä¸€è‡´é—®é¢˜
func (s *RocketMQProxyService) ValidateAndFixProducerRefCounts() {
	s.mu.Lock()
	defer s.mu.Unlock()

	log.Printf("ğŸ” Validating producer reference counts...")

	// ç»Ÿè®¡æ¯ä¸ªç”Ÿäº§è€…å®ä¾‹çš„å®é™…å¼•ç”¨æ•°
	actualRefCounts := make(map[rocketmq.Producer]int)

	for _, producerInfo := range s.producers {
		actualRefCounts[producerInfo.Producer]++
	}

	// æ£€æŸ¥å¹¶ä¿®å¤å¼•ç”¨è®¡æ•°ä¸ä¸€è‡´
	fixedCount := 0
	for _, producerInfo := range s.producers {
		expectedCount := actualRefCounts[producerInfo.Producer]
		if producerInfo.RefCount != expectedCount {
			log.Printf("âš ï¸ Reference count mismatch detected: Producer has RefCount=%d, but actual references=%d. Fixing...",
				producerInfo.RefCount, expectedCount)
			producerInfo.RefCount = expectedCount
			fixedCount++
		}
	}

	if fixedCount > 0 {
		log.Printf("ğŸ”§ Fixed %d producer reference count mismatches", fixedCount)
	} else {
		log.Printf("âœ… All producer reference counts are consistent")
	}
}

// cleanupSharedConsumerInternal æ¸…ç†å…±äº«æ¶ˆè´¹è€…æ˜ å°„
func (s *RocketMQProxyService) cleanupSharedConsumerInternal(consumerKey ConsumerKey, consumerID string) {
	// ä»å…±äº«æ˜ å°„ä¸­åˆ é™¤
	delete(s.sharedConsumers, consumerKey)

	// å¦‚æœæ¶ˆè´¹è€…è¿˜å­˜åœ¨ï¼Œä¹Ÿæ¸…ç†æ‰
	if consumerInfo, exists := s.consumers[consumerID]; exists {
		log.Printf("ğŸ§¹ Cleaning up shared consumer: ID=%s, Group=%s, Topics=%v",
			consumerID, consumerInfo.GroupID, getTopicList(consumerInfo.Topics))

		// å–æ¶ˆæ¶ˆè´¹è€…ä¸Šä¸‹æ–‡
		if consumerInfo.CancelFunc != nil {
			consumerInfo.CancelFunc()
		}

		// åœæ­¢æ¶ˆè´¹è€…
		if err := consumerInfo.Consumer.Shutdown(); err != nil {
			log.Printf("âš ï¸ Error shutting down shared consumer %s: %v", consumerID, err)
		}

		// å…³é—­æ¶ˆæ¯é€šé“
		if consumerInfo.MessageChan != nil {
			close(consumerInfo.MessageChan)
		}

		// ä»mapä¸­ç§»é™¤
		delete(s.consumers, consumerID)

		// å‡å°‘æ¶ˆè´¹è€…è®¡æ•°
		metrics.GlobalMetrics.DecActiveConsumers()
	}
}

// getTopicList è·å–æ¶ˆè´¹è€…è®¢é˜…çš„Topicåˆ—è¡¨
func getTopicList(topics map[string]bool) string {
	topicList := make([]string, 0, len(topics))
	for topic := range topics {
		topicList = append(topicList, topic)
	}
	return fmt.Sprintf("%v", topicList)
}
