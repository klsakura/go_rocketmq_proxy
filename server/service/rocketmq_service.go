package service

import (
	"context"
	"fmt"
	"log"
	"sync"
	"time"

	"go_rocketmq_sdk/proto"
	"go_rocketmq_sdk/server/config"
	"go_rocketmq_sdk/server/metrics"

	"github.com/apache/rocketmq-client-go/v2"
	"github.com/apache/rocketmq-client-go/v2/consumer"
	"github.com/apache/rocketmq-client-go/v2/primitive"
	"github.com/apache/rocketmq-client-go/v2/producer"
	"github.com/google/uuid"
	"google.golang.org/grpc/codes"
	"google.golang.org/grpc/status"
)

// ProducerInfo ç”Ÿäº§è€…ä¿¡æ¯
type ProducerInfo struct {
	Producer   rocketmq.Producer
	Topic      string
	Endpoint   string
	InstanceId string
	RefCount   int       // å¼•ç”¨è®¡æ•°ï¼Œæ”¯æŒå¤ç”¨
	LastActive time.Time // æœ€åæ´»è·ƒæ—¶é—´ï¼Œç”¨äºè¶…æ—¶æ¸…ç†
	CreatedAt  time.Time // åˆ›å»ºæ—¶é—´
}

// ConsumerInfo æ¶ˆè´¹è€…ä¿¡æ¯
type ConsumerInfo struct {
	Consumer    rocketmq.PushConsumer
	Topic       string
	GroupID     string
	Endpoint    string
	InstanceId  string
	MessageChan chan *proto.Message
	CancelFunc  context.CancelFunc // ç”¨äºå–æ¶ˆæ¶ˆè´¹è€…ä¸Šä¸‹æ–‡
	LastActive  time.Time          // æœ€åæ´»è·ƒæ—¶é—´
}

// ConnectionKey è¿æ¥å”¯ä¸€æ ‡è¯†
type ConnectionKey struct {
	Endpoint    string
	AccessKeyId string
	InstanceId  string
	Topic       string
}

// RocketMQProxyService gRPCæœåŠ¡å®ç°
type RocketMQProxyService struct {
	proto.UnimplementedRocketMQProxyServer
	producers       map[string]*ProducerInfo // producer_id -> ProducerInfo
	consumers       map[string]*ConsumerInfo // consumer_id -> ConsumerInfo
	sharedProducers map[ConnectionKey]string // è¿æ¥é…ç½® -> producer_id (æ”¯æŒå¤šå®ä¾‹)
	mu              sync.RWMutex
	config          *config.ServerConfig // æœåŠ¡é…ç½®
}

// NewRocketMQProxyService åˆ›å»ºæ–°çš„æœåŠ¡å®ä¾‹
func NewRocketMQProxyService(cfg *config.ServerConfig) *RocketMQProxyService {
	return &RocketMQProxyService{
		producers:       make(map[string]*ProducerInfo),
		consumers:       make(map[string]*ConsumerInfo),
		sharedProducers: make(map[ConnectionKey]string),
		config:          cfg,
	}
}

// CreateProducer åˆ›å»ºç”Ÿäº§è€…
func (s *RocketMQProxyService) CreateProducer(ctx context.Context, req *proto.CreateProducerRequest) (*proto.CreateProducerResponse, error) {
	log.Printf("Creating producer for topic: %s, instance: %s, endpoint: %s", req.Topic, req.InstanceId, req.Endpoint)

	// ç”Ÿæˆè¿æ¥keyï¼Œæ”¯æŒå¤šä¸ªRocketMQå®ä¾‹
	connKey := ConnectionKey{
		Endpoint:    req.Endpoint,
		AccessKeyId: req.AccessKeyId,
		InstanceId:  req.InstanceId,
		Topic:       req.Topic,
	}

	s.mu.Lock()
	defer s.mu.Unlock()

	// æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒé…ç½®çš„ç”Ÿäº§è€…å¯ä»¥å¤ç”¨
	if existingProducerID, exists := s.sharedProducers[connKey]; exists {
		if producerInfo, found := s.producers[existingProducerID]; found {
			// ç”Ÿæˆæ–°çš„IDä½†å¤ç”¨åŒä¸€ä¸ªç”Ÿäº§è€…å®ä¾‹
			newProducerID := uuid.New().String()
			s.producers[newProducerID] = &ProducerInfo{
				Producer:   producerInfo.Producer,
				Topic:      producerInfo.Topic,
				Endpoint:   producerInfo.Endpoint,
				InstanceId: producerInfo.InstanceId,
				RefCount:   producerInfo.RefCount + 1,
				LastActive: producerInfo.LastActive,
				CreatedAt:  producerInfo.CreatedAt,
			}
			producerInfo.RefCount++

			log.Printf("âœ… Reusing producer: ID=%s, Topic=%s, Instance=%s, RefCount=%d",
				newProducerID, req.Topic, req.InstanceId, producerInfo.RefCount)
			return &proto.CreateProducerResponse{
				Success:    true,
				Message:    fmt.Sprintf("Producer reused (ref: %d)", producerInfo.RefCount),
				ProducerId: newProducerID,
			}, nil
		}
	}

	// åˆ›å»ºæ–°çš„ç”Ÿäº§è€…
	// ä½¿ç”¨ç®€å•çš„ç”Ÿäº§è€…ç»„åï¼Œä¸åŒ…å«å®ä¾‹ID
	producerGroup := fmt.Sprintf("grpc_proxy_producer_%d", time.Now().UnixNano())

	// åˆ›å»ºç”Ÿäº§è€…é…ç½® - æŒ‰ç…§å®˜æ–¹ç¤ºä¾‹
	opts := []producer.Option{
		// ä½¿ç”¨å®˜æ–¹æ¨èçš„NameServeré…ç½®æ–¹å¼
		producer.WithNsResolver(primitive.NewPassthroughResolver([]string{req.Endpoint})),
		producer.WithCredentials(primitive.Credentials{
			AccessKey: req.AccessKeyId,
			SecretKey: req.AccessKeySecret,
		}),
		producer.WithGroupName(producerGroup),
		producer.WithRetry(2),
	}

	// åˆ›å»ºç”Ÿäº§è€…
	p, err := rocketmq.NewProducer(opts...)
	if err != nil {
		return &proto.CreateProducerResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to create producer: %v", err),
		}, nil
	}

	// å¯åŠ¨ç”Ÿäº§è€…
	err = p.Start()
	if err != nil {
		return &proto.CreateProducerResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to start producer: %v", err),
		}, nil
	}

	// ç”Ÿæˆå”¯ä¸€ID
	producerID := uuid.New().String()

	// å­˜å‚¨ç”Ÿäº§è€…ä¿¡æ¯
	s.producers[producerID] = &ProducerInfo{
		Producer:   p,
		Topic:      req.Topic,
		Endpoint:   req.Endpoint,
		InstanceId: req.InstanceId,
		RefCount:   1,
		LastActive: time.Now(),
		CreatedAt:  time.Now(),
	}

	// è®°å½•å¤ç”¨æ˜ å°„
	s.sharedProducers[connKey] = producerID

	// å¢åŠ ç”Ÿäº§è€…è®¡æ•°
	metrics.GlobalMetrics.IncActiveProducers()

	log.Printf("ğŸš€ New producer created: ID=%s, Group=%s, Topic=%s, Instance=%s",
		producerID, producerGroup, req.Topic, req.InstanceId)
	return &proto.CreateProducerResponse{
		Success:    true,
		Message:    "Producer created successfully",
		ProducerId: producerID,
	}, nil
}

// SendMessage å‘é€æ¶ˆæ¯
func (s *RocketMQProxyService) SendMessage(ctx context.Context, req *proto.SendMessageRequest) (*proto.SendMessageResponse, error) {
	log.Printf("Sending message with producer: %s", req.ProducerId)

	// è·å–ç”Ÿäº§è€…
	s.mu.RLock()
	producerInfo, exists := s.producers[req.ProducerId]
	s.mu.RUnlock()

	if !exists {
		return &proto.SendMessageResponse{
			Success: false,
			Message: "Producer not found",
		}, status.Error(codes.NotFound, "Producer not found")
	}

	// æ›´æ–°ç”Ÿäº§è€…æœ€åæ´»è·ƒæ—¶é—´
	s.mu.Lock()
	if info, ok := s.producers[req.ProducerId]; ok {
		info.LastActive = time.Now()
	}
	s.mu.Unlock()

	// æ„å»ºæ¶ˆæ¯
	msg := &primitive.Message{
		Topic: producerInfo.Topic,
		Body:  []byte(req.MessageBody),
	}

	// è®¾ç½®Tag
	if req.Tag != "" {
		msg.WithTag(req.Tag)
	}

	// å¤„ç†æ¶ˆæ¯å±æ€§
	if req.Properties != nil {
		// è®¾ç½®è‡ªå®šä¹‰å±æ€§
		for k, v := range req.Properties.Properties {
			msg.WithProperty(k, v)
		}

		// è®¾ç½®æ¶ˆæ¯Key
		if req.Properties.MessageKey != "" {
			msg.WithKeys([]string{req.Properties.MessageKey})
		}

		// è®¾ç½®åˆ†åŒºé”®(é¡ºåºæ¶ˆæ¯)
		if req.Properties.ShardingKey != "" {
			msg.WithShardingKey(req.Properties.ShardingKey)
		}

		// è®¾ç½®å»¶æ—¶æŠ•é€’æ—¶é—´ - æ”¯æŒå­—èŠ‚äº‘çš„ä»»æ„ç²¾åº¦å»¶æ—¶æ¶ˆæ¯
		if req.Properties.StartDeliverTime > 0 {
			// ä½¿ç”¨å­—èŠ‚äº‘çš„ __STARTDELIVERTIME å±æ€§å®ç°ä»»æ„ç²¾åº¦å»¶æ—¶
			msg.WithProperty("__STARTDELIVERTIME", fmt.Sprintf("%d", req.Properties.StartDeliverTime))
			log.Printf("Using arbitrary precision delay with __STARTDELIVERTIME: %d", req.Properties.StartDeliverTime)
		}
	}

	// å‘é€æ¶ˆæ¯
	result, err := producerInfo.Producer.SendSync(ctx, msg)
	if err != nil {
		metrics.GlobalMetrics.IncErrorCount()
		return &proto.SendMessageResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to send message: %v", err),
		}, nil
	}

	// å¢åŠ å‘é€æ¶ˆæ¯è®¡æ•°
	metrics.GlobalMetrics.IncMessagesSent()

	return &proto.SendMessageResponse{
		Success:       true,
		Message:       "Message sent successfully",
		MessageId:     result.MsgID,
		ReceiptHandle: result.MsgID,
	}, nil
}

// SendOrderedMessage å‘é€é¡ºåºæ¶ˆæ¯
func (s *RocketMQProxyService) SendOrderedMessage(ctx context.Context, req *proto.SendOrderedMessageRequest) (*proto.SendMessageResponse, error) {
	log.Printf("Sending ordered message with producer: %s, sharding key: %s", req.ProducerId, req.ShardingKey)

	// è·å–ç”Ÿäº§è€…
	s.mu.RLock()
	producerInfo, exists := s.producers[req.ProducerId]
	s.mu.RUnlock()

	if !exists {
		return &proto.SendMessageResponse{
			Success: false,
			Message: "Producer not found",
		}, status.Error(codes.NotFound, "Producer not found")
	}

	// æ„å»ºé¡ºåºæ¶ˆæ¯
	msg := &primitive.Message{
		Topic: producerInfo.Topic,
		Body:  []byte(req.MessageBody),
	}

	// è®¾ç½®Tag
	if req.Tag != "" {
		msg.WithTag(req.Tag)
	}

	// è®¾ç½®åˆ†åŒºé”®ï¼ˆé¡ºåºæ¶ˆæ¯çš„å…³é”®ï¼‰
	if req.ShardingKey != "" {
		msg.WithShardingKey(req.ShardingKey)
	}

	// å¤„ç†æ¶ˆæ¯å±æ€§
	if req.Properties != nil {
		for k, v := range req.Properties.Properties {
			msg.WithProperty(k, v)
		}
		if req.Properties.MessageKey != "" {
			msg.WithKeys([]string{req.Properties.MessageKey})
		}
	}

	// å‘é€é¡ºåºæ¶ˆæ¯
	result, err := producerInfo.Producer.SendSync(ctx, msg)
	if err != nil {
		metrics.GlobalMetrics.IncErrorCount()
		return &proto.SendMessageResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to send ordered message: %v", err),
		}, nil
	}

	metrics.GlobalMetrics.IncMessagesSent()
	log.Printf("âœ… Ordered message sent successfully: %s", result.MsgID)

	return &proto.SendMessageResponse{
		Success:       true,
		Message:       "Ordered message sent successfully",
		MessageId:     result.MsgID,
		ReceiptHandle: result.MsgID,
	}, nil
}

// SendDelayMessage å‘é€å»¶è¿Ÿæ¶ˆæ¯
func (s *RocketMQProxyService) SendDelayMessage(ctx context.Context, req *proto.SendDelayMessageRequest) (*proto.SendMessageResponse, error) {
	log.Printf("Sending delay message with producer: %s, delay level: %d, deliver time: %d",
		req.ProducerId, req.DelayTimeLevel, req.StartDeliverTime)

	// è·å–ç”Ÿäº§è€…
	s.mu.RLock()
	producerInfo, exists := s.producers[req.ProducerId]
	s.mu.RUnlock()

	if !exists {
		return &proto.SendMessageResponse{
			Success: false,
			Message: "Producer not found",
		}, status.Error(codes.NotFound, "Producer not found")
	}

	// æ„å»ºå»¶è¿Ÿæ¶ˆæ¯
	msg := &primitive.Message{
		Topic: producerInfo.Topic,
		Body:  []byte(req.MessageBody),
	}

	// è®¾ç½®Tag
	if req.Tag != "" {
		msg.WithTag(req.Tag)
	}

	// è®¾ç½®å»¶è¿Ÿæ—¶é—´ - æ”¯æŒå­—èŠ‚äº‘çš„ä»»æ„ç²¾åº¦å»¶æ—¶æ¶ˆæ¯
	if req.StartDeliverTime > 0 {
		// ä½¿ç”¨å­—èŠ‚äº‘çš„ __STARTDELIVERTIME å±æ€§å®ç°ä»»æ„ç²¾åº¦å»¶æ—¶
		msg.WithProperty("__STARTDELIVERTIME", fmt.Sprintf("%d", req.StartDeliverTime))
		log.Printf("Using arbitrary precision delay with __STARTDELIVERTIME: %d", req.StartDeliverTime)
	} else if req.DelayTimeLevel > 0 {
		// å…¼å®¹ä¼ ç»Ÿçš„å»¶è¿Ÿç­‰çº§ (1-18)ï¼Œä½¿ç”¨RocketMQåŸç”Ÿå»¶è¿Ÿç­‰çº§
		msg.WithDelayTimeLevel(int(req.DelayTimeLevel))
		log.Printf("Using traditional delay level: %d", req.DelayTimeLevel)
	}

	// å¤„ç†æ¶ˆæ¯å±æ€§
	if req.Properties != nil {
		for k, v := range req.Properties.Properties {
			msg.WithProperty(k, v)
		}
		if req.Properties.MessageKey != "" {
			msg.WithKeys([]string{req.Properties.MessageKey})
		}
	}

	// å‘é€å»¶è¿Ÿæ¶ˆæ¯
	result, err := producerInfo.Producer.SendSync(ctx, msg)
	if err != nil {
		metrics.GlobalMetrics.IncErrorCount()
		return &proto.SendMessageResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to send delay message: %v", err),
		}, nil
	}

	metrics.GlobalMetrics.IncMessagesSent()
	log.Printf("âœ… Delay message sent successfully: %s", result.MsgID)

	return &proto.SendMessageResponse{
		Success:       true,
		Message:       "Delay message sent successfully",
		MessageId:     result.MsgID,
		ReceiptHandle: result.MsgID,
	}, nil
}

// SendTransactionMessage å‘é€äº‹åŠ¡æ¶ˆæ¯
func (s *RocketMQProxyService) SendTransactionMessage(ctx context.Context, req *proto.SendTransactionMessageRequest) (*proto.SendTransactionMessageResponse, error) {
	log.Printf("Sending transaction message with producer: %s, immunity time: %d",
		req.ProducerId, req.TransCheckImmunityTime)

	// è·å–ç”Ÿäº§è€…
	s.mu.RLock()
	producerInfo, exists := s.producers[req.ProducerId]
	s.mu.RUnlock()

	if !exists {
		return &proto.SendTransactionMessageResponse{
			Success: false,
			Message: "Producer not found",
		}, status.Error(codes.NotFound, "Producer not found")
	}

	// æ„å»ºäº‹åŠ¡æ¶ˆæ¯
	msg := &primitive.Message{
		Topic: producerInfo.Topic,
		Body:  []byte(req.MessageBody),
	}

	// è®¾ç½®Tag
	if req.Tag != "" {
		msg.WithTag(req.Tag)
	}

	// è®¾ç½®äº‹åŠ¡å›æŸ¥å…ç–«æ—¶é—´
	if req.TransCheckImmunityTime > 0 {
		// RocketMQ Go SDKä¸­äº‹åŠ¡æ¶ˆæ¯çš„å¤„ç†æ–¹å¼
		msg.WithProperty("__STARTDELIVERTIME", fmt.Sprintf("%d", time.Now().Add(time.Duration(req.TransCheckImmunityTime)*time.Second).UnixMilli()))
	}

	// å¤„ç†æ¶ˆæ¯å±æ€§
	if req.Properties != nil {
		for k, v := range req.Properties.Properties {
			msg.WithProperty(k, v)
		}
		if req.Properties.MessageKey != "" {
			msg.WithKeys([]string{req.Properties.MessageKey})
		}
	}

	// å‘é€äº‹åŠ¡æ¶ˆæ¯ï¼ˆè¿™é‡Œä½¿ç”¨æ™®é€šå‘é€ï¼Œå®é™…äº‹åŠ¡é€»è¾‘éœ€è¦æ›´å¤æ‚çš„å¤„ç†ï¼‰
	result, err := producerInfo.Producer.SendSync(ctx, msg)
	if err != nil {
		metrics.GlobalMetrics.IncErrorCount()
		return &proto.SendTransactionMessageResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to send transaction message: %v", err),
		}, nil
	}

	metrics.GlobalMetrics.IncMessagesSent()
	log.Printf("âœ… Transaction message sent successfully: %s", result.MsgID)

	return &proto.SendTransactionMessageResponse{
		Success:       true,
		Message:       "Transaction message sent successfully",
		MessageId:     result.MsgID,
		ReceiptHandle: result.MsgID,
		TransactionId: fmt.Sprintf("trans_%s_%d", result.MsgID, time.Now().UnixNano()),
	}, nil
}

// CreateConsumer åˆ›å»ºæ¶ˆè´¹è€…
func (s *RocketMQProxyService) CreateConsumer(ctx context.Context, req *proto.CreateConsumerRequest) (*proto.CreateConsumerResponse, error) {
	log.Printf("Creating consumer for topic: %s, group: %s", req.Topic, req.GroupId)

	// æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒç»„åçš„æ¶ˆè´¹è€…
	s.mu.Lock()
	for consumerID, existingConsumer := range s.consumers {
		if existingConsumer.GroupID == req.GroupId && existingConsumer.Topic == req.Topic {
			// æ£€æŸ¥ç°æœ‰æ¶ˆè´¹è€…æ˜¯å¦è¿˜æ´»è·ƒ
			timeSinceLastActive := time.Since(existingConsumer.LastActive)

			if timeSinceLastActive > 30*time.Second {
				// è¶…è¿‡30ç§’æœªæ´»è·ƒï¼Œå¼ºåˆ¶æ¸…ç†æ—§çš„æ¶ˆè´¹è€…
				log.Printf("ğŸ”„ Found inactive consumer with same group name, replacing: %s (inactive for %v)", consumerID, timeSinceLastActive)
				s.mu.Unlock() // é‡Šæ”¾é”åæ¸…ç†
				if err := s.CleanupConsumerByID(consumerID); err != nil {
					log.Printf("âš ï¸ Error cleaning up existing consumer: %v", err)
				}
				s.mu.Lock() // é‡æ–°è·å–é”
				break       // è·³å‡ºå¾ªç¯ï¼Œç»§ç»­åˆ›å»ºæ–°çš„æ¶ˆè´¹è€…
			} else {
				// æ¶ˆè´¹è€…ä»ç„¶æ´»è·ƒï¼Œæ‹’ç»åˆ›å»º
				s.mu.Unlock()
				return &proto.CreateConsumerResponse{
					Success: false,
					Message: fmt.Sprintf("Consumer group '%s' for topic '%s' is still active (last active: %v ago). Please wait or use a different group name.", req.GroupId, req.Topic, timeSinceLastActive.Truncate(time.Second)),
				}, nil
			}
		}
	}
	s.mu.Unlock()

	// ç›´æ¥ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ç»„åï¼ˆæ”¯æŒé¢„å®šä¹‰ç»„åï¼‰
	consumerGroup := req.GroupId

	// åˆ›å»ºå¸¦å–æ¶ˆåŠŸèƒ½çš„ä¸Šä¸‹æ–‡
	consumerCtx, cancelFunc := context.WithCancel(context.Background())

	// åˆ›å»ºæ¶ˆè´¹è€…é…ç½® - æŒ‰ç…§å®˜æ–¹ç¤ºä¾‹
	opts := []consumer.Option{
		// ä½¿ç”¨å®˜æ–¹æ¨èçš„NameServeré…ç½®æ–¹å¼
		consumer.WithNsResolver(primitive.NewPassthroughResolver([]string{req.Endpoint})),
		consumer.WithCredentials(primitive.Credentials{
			AccessKey: req.AccessKeyId,
			SecretKey: req.AccessKeySecret,
		}),
		consumer.WithGroupName(consumerGroup),
		consumer.WithConsumeFromWhere(consumer.ConsumeFromLastOffset),
		// é…ç½®æ‹‰å–å‚æ•°ä»¥å‡å°‘è¶…æ—¶è­¦å‘Š
		consumer.WithConsumerPullTimeout(s.config.PullTimeout), // ä½¿ç”¨é…ç½®çš„æ‹‰å–è¶…æ—¶æ—¶é—´
		consumer.WithPullInterval(s.config.PullInterval),       // ä½¿ç”¨é…ç½®çš„æ‹‰å–é—´éš”
		consumer.WithMaxReconsumeTimes(3),                      // æœ€å¤§é‡è¯•æ¬¡æ•°
		consumer.WithConsumeMessageBatchMaxSize(32),            // æ‰¹é‡æ¶ˆè´¹å¤§å°
	}

	// åˆ›å»ºæ¶ˆè´¹è€…
	c, err := rocketmq.NewPushConsumer(opts...)
	if err != nil {
		cancelFunc() // æ¸…ç†ä¸Šä¸‹æ–‡
		return &proto.CreateConsumerResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to create consumer: %v", err),
		}, nil
	}

	// ç”Ÿæˆå”¯ä¸€ID
	consumerID := uuid.New().String()

	// åˆ›å»ºæ¶ˆæ¯é€šé“
	messageChan := make(chan *proto.Message, s.config.MessageBufferSize)

	// è®¢é˜…ä¸»é¢˜
	selector := consumer.MessageSelector{
		Type:       consumer.TAG,
		Expression: req.TagExpression,
	}

	err = c.Subscribe(req.Topic, selector, func(ctx context.Context, msgs ...*primitive.MessageExt) (consumer.ConsumeResult, error) {
		// æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦å·²å–æ¶ˆ
		select {
		case <-consumerCtx.Done():
			return consumer.ConsumeRetryLater, fmt.Errorf("consumer context cancelled")
		default:
		}

		// å°†æ¶ˆæ¯å‘é€åˆ°é€šé“
		for _, msg := range msgs {
			// å¢åŠ æ¥æ”¶æ¶ˆæ¯è®¡æ•°
			metrics.GlobalMetrics.IncMessagesReceived()

			protoMsg := &proto.Message{
				MessageId:      msg.MsgId,
				ReceiptHandle:  msg.MsgId,
				MessageBody:    string(msg.Body),
				Tag:            msg.GetTags(),
				Properties:     msg.GetProperties(),
				BornTimestamp:  msg.BornTimestamp,
				ReconsumeTimes: int32(msg.ReconsumeTimes),
			}

			// ä½¿ç”¨å¸¦è¶…æ—¶çš„å‘é€ï¼Œé¿å…æ¶ˆæ¯ä¸¢å¤±
			select {
			case messageChan <- protoMsg:
				log.Printf("Message sent to channel: %s", msg.MsgId)
			case <-consumerCtx.Done():
				log.Printf("Consumer context cancelled, dropping message: %s", msg.MsgId)
				return consumer.ConsumeRetryLater, fmt.Errorf("consumer context cancelled")
			case <-time.After(5 * time.Second):
				log.Printf("âš ï¸ Message channel send timeout, will retry later: %s", msg.MsgId)
				// å¢åŠ channelæ»¡äº‹ä»¶è®¡æ•°
				metrics.GlobalMetrics.IncChannelFullEvents()
				return consumer.ConsumeRetryLater, fmt.Errorf("message channel timeout - will retry")
			}
		}
		return consumer.ConsumeSuccess, nil
	})

	if err != nil {
		cancelFunc() // æ¸…ç†ä¸Šä¸‹æ–‡
		return &proto.CreateConsumerResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to subscribe topic: %v", err),
		}, nil
	}

	// å¯åŠ¨æ¶ˆè´¹è€…
	err = c.Start()
	if err != nil {
		cancelFunc() // æ¸…ç†ä¸Šä¸‹æ–‡
		return &proto.CreateConsumerResponse{
			Success: false,
			Message: fmt.Sprintf("Failed to start consumer: %v", err),
		}, nil
	}

	// å­˜å‚¨æ¶ˆè´¹è€…ä¿¡æ¯
	s.mu.Lock()
	s.consumers[consumerID] = &ConsumerInfo{
		Consumer:    c,
		Topic:       req.Topic,
		GroupID:     consumerGroup,
		Endpoint:    req.Endpoint,
		InstanceId:  req.InstanceId,
		MessageChan: messageChan,
		CancelFunc:  cancelFunc,
		LastActive:  time.Now(),
	}
	s.mu.Unlock()

	// å¢åŠ æ¶ˆè´¹è€…è®¡æ•°
	metrics.GlobalMetrics.IncActiveConsumers()

	log.Printf("âœ… Consumer created successfully: ID=%s, Group=%s (supports predefined groups)", consumerID, consumerGroup)
	return &proto.CreateConsumerResponse{
		Success:    true,
		Message:    fmt.Sprintf("Consumer created successfully for predefined group: %s", consumerGroup),
		ConsumerId: consumerID,
	}, nil
}

// ReceiveMessages æ¥æ”¶æ¶ˆæ¯(æµå¼)
func (s *RocketMQProxyService) ReceiveMessages(req *proto.ReceiveMessagesRequest, stream proto.RocketMQProxy_ReceiveMessagesServer) error {
	log.Printf("ğŸ¬ Starting message stream for consumer: %s", req.ConsumerId)

	// è·å–æ¶ˆè´¹è€…
	s.mu.RLock()
	consumerInfo, exists := s.consumers[req.ConsumerId]
	s.mu.RUnlock()

	if !exists {
		return status.Error(codes.NotFound, "Consumer not found")
	}

	// æ›´æ–°æœ€åæ´»è·ƒæ—¶é—´
	s.mu.Lock()
	if info, ok := s.consumers[req.ConsumerId]; ok {
		info.LastActive = time.Now()
	}
	s.mu.Unlock()

	// åˆ›å»ºå—æ§çš„ä¸Šä¸‹æ–‡
	ctx, cancel := context.WithCancel(stream.Context())
	defer cancel()

	// ç¼©çŸ­å¿ƒè·³é—´éš”ï¼Œæ›´å¿«æ£€æµ‹æ–­å¼€è¿æ¥
	heartbeatTicker := time.NewTicker(10 * time.Second)
	defer heartbeatTicker.Stop()

	// StreamçŠ¶æ€ç›‘æ§ - ä½¿ç”¨å—æ§çš„goroutine
	streamDone := make(chan bool, 1)
	go func() {
		defer func() {
			if r := recover(); r != nil {
				log.Printf("âš ï¸ Stream monitor goroutine recovered from panic: %v", r)
			}
		}()
		select {
		case <-ctx.Done():
			return
		case <-stream.Context().Done():
			select {
			case streamDone <- true:
			default:
			}
			return
		}
	}()

	// ç¡®ä¿åœ¨å‡½æ•°é€€å‡ºæ—¶æ¸…ç†æ¶ˆè´¹è€… - ç›´æ¥è°ƒç”¨ï¼Œä¸ä½¿ç”¨é¢å¤–goroutine
	defer func() {
		log.Printf("ğŸ”š Stream ended for consumer: %s, reason: client disconnection", req.ConsumerId)

		// ç›´æ¥æ¸…ç†ï¼Œé¿å…goroutineæ³„æ¼
		if err := s.CleanupConsumerByID(req.ConsumerId); err != nil {
			log.Printf("âŒ Error cleaning up consumer %s: %v", req.ConsumerId, err)
		} else {
			log.Printf("âœ… Consumer %s cleaned up immediately after stream end", req.ConsumerId)
		}
	}()

	log.Printf("ğŸ“¡ Consumer %s ready to receive messages (heartbeat: 10s)", req.ConsumerId)

	// ä»æ¶ˆæ¯é€šé“è¯»å–å¹¶å‘é€æ¶ˆæ¯
	for {
		select {
		case <-streamDone:
			log.Printf("ğŸ“´ Client disconnected for consumer: %s", req.ConsumerId)
			return nil

		case <-ctx.Done():
			log.Printf("ğŸ“´ Stream context done for consumer: %s", req.ConsumerId)
			return nil

		case msg, ok := <-consumerInfo.MessageChan:
			if !ok {
				// é€šé“å·²å…³é—­
				log.Printf("ğŸ“¨ Message channel closed for consumer: %s", req.ConsumerId)
				return nil
			}

			if err := stream.Send(msg); err != nil {
				log.Printf("âŒ Failed to send message to stream for consumer %s: %v", req.ConsumerId, err)
				return err
			}

			// æ›´æ–°æœ€åæ´»è·ƒæ—¶é—´
			s.mu.Lock()
			if info, ok := s.consumers[req.ConsumerId]; ok {
				info.LastActive = time.Now()
			}
			s.mu.Unlock()

		case <-heartbeatTicker.C:
			// å‘é€å¿ƒè·³ï¼Œæ›´æ–°æ´»è·ƒæ—¶é—´
			s.mu.Lock()
			if info, ok := s.consumers[req.ConsumerId]; ok {
				info.LastActive = time.Now()
				log.Printf("ğŸ’“ Heartbeat for consumer: %s (group: %s)", req.ConsumerId, info.GroupID)
			}
			s.mu.Unlock()
		}
	}
}

// AckMessage ç¡®è®¤æ¶ˆæ¯
func (s *RocketMQProxyService) AckMessage(ctx context.Context, req *proto.AckMessageRequest) (*proto.AckMessageResponse, error) {
	log.Printf("Acking message for consumer: %s", req.ConsumerId)

	// åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œåº”è¯¥ç¡®è®¤å…·ä½“çš„æ¶ˆæ¯
	// RocketMQçš„ç¡®è®¤æ˜¯åœ¨æ¶ˆè´¹å›è°ƒä¸­å¤„ç†çš„ï¼Œè¿™é‡Œå¯ä»¥è®°å½•ç¡®è®¤çŠ¶æ€

	return &proto.AckMessageResponse{
		Success: true,
		Message: "Message acknowledged",
	}, nil
}

// CleanupProducer æ¸…ç†ç”Ÿäº§è€… (gRPC API)
func (s *RocketMQProxyService) CleanupProducer(ctx context.Context, req *proto.CleanupProducerRequest) (*proto.CleanupProducerResponse, error) {
	log.Printf("ğŸ§¹ Manual producer cleanup request - ProducerID: %s, Topic: %s, Endpoint: %s", req.ProducerId, req.Topic, req.Endpoint)

	cleanedCount := int32(0)
	var cleanupErrors []string

	s.mu.Lock()
	var toCleanup []string

	if req.ProducerId != "" {
		// é€šè¿‡ç”Ÿäº§è€…IDæ¸…ç†
		if _, exists := s.producers[req.ProducerId]; exists {
			toCleanup = append(toCleanup, req.ProducerId)
		}
	} else if req.Topic != "" {
		// é€šè¿‡ä¸»é¢˜æ¸…ç†ï¼ˆå¯é€‰é…åˆEndpointï¼‰
		for producerID, producerInfo := range s.producers {
			if producerInfo.Topic == req.Topic {
				if req.Endpoint == "" || producerInfo.Endpoint == req.Endpoint {
					toCleanup = append(toCleanup, producerID)
				}
			}
		}
	}
	s.mu.Unlock()

	// æ‰§è¡Œæ¸…ç†
	for _, producerID := range toCleanup {
		if err := s.cleanupProducerInternal(producerID); err != nil {
			cleanupErrors = append(cleanupErrors, fmt.Sprintf("Producer %s: %v", producerID, err))
		} else {
			cleanedCount++
			log.Printf("âœ… Manually cleaned up producer: %s", producerID)
		}
	}

	// æ„å»ºå“åº”æ¶ˆæ¯
	var message string
	success := len(cleanupErrors) == 0

	if cleanedCount > 0 {
		message = fmt.Sprintf("Successfully cleaned up %d producer(s)", cleanedCount)
		if len(cleanupErrors) > 0 {
			message += fmt.Sprintf(", but %d failed: %v", len(cleanupErrors), cleanupErrors)
		}
	} else {
		if req.ProducerId != "" {
			message = "No producer found with the specified ID"
		} else {
			message = "No producers found matching the criteria"
		}
	}

	return &proto.CleanupProducerResponse{
		Success:      success,
		Message:      message,
		CleanedCount: cleanedCount,
	}, nil
}

// cleanupProducerInternal å†…éƒ¨ç”Ÿäº§è€…æ¸…ç†æ–¹æ³•
func (s *RocketMQProxyService) cleanupProducerInternal(producerID string) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	producerInfo, exists := s.producers[producerID]
	if !exists {
		return fmt.Errorf("producer not found: %s", producerID)
	}

	log.Printf("ğŸ§¹ Cleaning up producer: ID=%s, Topic=%s, Endpoint=%s, RefCount=%d",
		producerID, producerInfo.Topic, producerInfo.Endpoint, producerInfo.RefCount)

	// å‡å°‘å¼•ç”¨è®¡æ•°
	producerInfo.RefCount--

	// å¦‚æœå¼•ç”¨è®¡æ•°å¤§äº0ï¼Œåªæ˜¯ç§»é™¤å½“å‰IDï¼Œä½†ä¿æŒç”Ÿäº§è€…å®ä¾‹
	if producerInfo.RefCount > 0 {
		delete(s.producers, producerID)
		log.Printf("âœ… Producer instance preserved with RefCount=%d", producerInfo.RefCount)
		return nil
	}

	// å¼•ç”¨è®¡æ•°ä¸º0ï¼ŒçœŸæ­£æ¸…ç†èµ„æº
	if err := producerInfo.Producer.Shutdown(); err != nil {
		log.Printf("âš ï¸ Error shutting down producer %s: %v", producerID, err)
	}

	// ä»æ˜ å°„ä¸­åˆ é™¤
	delete(s.producers, producerID)

	// æ¸…ç†å…±äº«æ˜ å°„
	for key, id := range s.sharedProducers {
		if id == producerID {
			delete(s.sharedProducers, key)
			break
		}
	}

	// å‡å°‘ç”Ÿäº§è€…è®¡æ•°
	metrics.GlobalMetrics.DecActiveProducers()

	log.Printf("âœ… Producer cleanup completed: %s", producerID)
	return nil
}

// CleanupInactiveProducers æ¸…ç†ä¸æ´»è·ƒçš„ç”Ÿäº§è€…ï¼ˆå®šæ—¶ä»»åŠ¡ï¼‰
func (s *RocketMQProxyService) CleanupInactiveProducers(timeout time.Duration) {
	var toCleanup []string

	// åªåœ¨è¯»å–æ—¶è·å–é”
	func() {
		s.mu.RLock()
		defer s.mu.RUnlock()

		now := time.Now()
		for producerID, producerInfo := range s.producers {
			if now.Sub(producerInfo.LastActive) > timeout {
				toCleanup = append(toCleanup, producerID)
			}
		}
	}()

	// é‡Šæ”¾é”åæ¸…ç†
	for _, producerID := range toCleanup {
		log.Printf("ğŸ•’ Cleaning up inactive producer: %s", producerID)
		if err := s.cleanupProducerInternal(producerID); err != nil {
			log.Printf("âŒ Error cleaning up inactive producer %s: %v", producerID, err)
		}
	}
}

// CleanupConsumerByID æ¸…ç†æŒ‡å®šçš„æ¶ˆè´¹è€…ï¼ˆå¤–éƒ¨è°ƒç”¨ï¼ŒåŒ…å«é”ç®¡ç†ï¼‰
func (s *RocketMQProxyService) CleanupConsumerByID(consumerID string) error {
	return s.cleanupConsumerInternal(consumerID)
}

// cleanupConsumerInternal å†…éƒ¨æ¸…ç†æ–¹æ³•ï¼ˆä¸ç®¡ç†é”ï¼Œä¾›å†…éƒ¨è°ƒç”¨ï¼‰
func (s *RocketMQProxyService) cleanupConsumerInternal(consumerID string) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	consumerInfo, exists := s.consumers[consumerID]
	if !exists {
		return fmt.Errorf("consumer not found: %s", consumerID)
	}

	log.Printf("ğŸ§¹ Cleaning up consumer: ID=%s, Group=%s, Topic=%s",
		consumerID, consumerInfo.GroupID, consumerInfo.Topic)

	// å–æ¶ˆæ¶ˆè´¹è€…ä¸Šä¸‹æ–‡
	if consumerInfo.CancelFunc != nil {
		consumerInfo.CancelFunc()
	}

	// åœæ­¢æ¶ˆè´¹è€…
	if err := consumerInfo.Consumer.Shutdown(); err != nil {
		log.Printf("âš ï¸ Error shutting down consumer %s: %v", consumerID, err)
	}

	// å…³é—­æ¶ˆæ¯é€šé“
	close(consumerInfo.MessageChan)

	// ä»mapä¸­ç§»é™¤
	delete(s.consumers, consumerID)

	// å‡å°‘æ¶ˆè´¹è€…è®¡æ•°
	metrics.GlobalMetrics.DecActiveConsumers()

	log.Printf("âœ… Consumer cleanup completed: %s", consumerID)
	return nil
}

// CleanupInactiveConsumers æ¸…ç†ä¸æ´»è·ƒçš„æ¶ˆè´¹è€…ï¼ˆå®šæ—¶ä»»åŠ¡ï¼‰
func (s *RocketMQProxyService) CleanupInactiveConsumers(timeout time.Duration) {
	var toCleanup []string

	// åªåœ¨è¯»å–æ—¶è·å–é”ï¼Œé¿å…åŒé‡è§£é”é—®é¢˜
	func() {
		s.mu.RLock()
		defer s.mu.RUnlock()

		now := time.Now()
		for consumerID, consumerInfo := range s.consumers {
			if now.Sub(consumerInfo.LastActive) > timeout {
				toCleanup = append(toCleanup, consumerID)
			}
		}
	}()

	// é‡Šæ”¾é”åæ¸…ç†
	for _, consumerID := range toCleanup {
		log.Printf("ğŸ•’ Cleaning up inactive consumer: %s", consumerID)
		if err := s.CleanupConsumerByID(consumerID); err != nil {
			log.Printf("âŒ Error cleaning up inactive consumer %s: %v", consumerID, err)
		}
	}
}

// CleanupConsumer æ¸…ç†æ¶ˆè´¹è€… (gRPC API)
func (s *RocketMQProxyService) CleanupConsumer(ctx context.Context, req *proto.CleanupConsumerRequest) (*proto.CleanupConsumerResponse, error) {
	log.Printf("ğŸ§¹ Manual cleanup request - ConsumerID: %s, GroupID: %s, Topic: %s", req.ConsumerId, req.GroupId, req.Topic)

	cleanedCount := int32(0)
	var cleanupErrors []string

	s.mu.Lock()
	var toCleanup []string

	if req.ConsumerId != "" {
		// é€šè¿‡æ¶ˆè´¹è€…IDæ¸…ç†
		if _, exists := s.consumers[req.ConsumerId]; exists {
			toCleanup = append(toCleanup, req.ConsumerId)
		}
	} else if req.GroupId != "" {
		// é€šè¿‡ç»„åæ¸…ç†ï¼ˆå¯é€‰é…åˆTopicï¼‰
		for consumerID, consumerInfo := range s.consumers {
			if consumerInfo.GroupID == req.GroupId {
				if req.Topic == "" || consumerInfo.Topic == req.Topic {
					toCleanup = append(toCleanup, consumerID)
				}
			}
		}
	}
	s.mu.Unlock()

	// æ‰§è¡Œæ¸…ç†
	for _, consumerID := range toCleanup {
		if err := s.cleanupConsumerInternal(consumerID); err != nil {
			cleanupErrors = append(cleanupErrors, fmt.Sprintf("Consumer %s: %v", consumerID, err))
		} else {
			cleanedCount++
			log.Printf("âœ… Manually cleaned up consumer: %s", consumerID)
		}
	}

	// æ„å»ºå“åº”æ¶ˆæ¯
	var message string
	success := len(cleanupErrors) == 0

	if cleanedCount > 0 {
		message = fmt.Sprintf("Successfully cleaned up %d consumer(s)", cleanedCount)
		if len(cleanupErrors) > 0 {
			message += fmt.Sprintf(", but %d failed: %v", len(cleanupErrors), cleanupErrors)
		}
	} else {
		if req.ConsumerId != "" {
			message = "No consumer found with the specified ID"
		} else {
			message = "No consumers found matching the criteria"
		}
	}

	return &proto.CleanupConsumerResponse{
		Success:      success,
		Message:      message,
		CleanedCount: cleanedCount,
	}, nil
}

// HealthCheck å¥åº·æ£€æŸ¥
func (s *RocketMQProxyService) HealthCheck(ctx context.Context, req *proto.HealthCheckRequest) (*proto.HealthCheckResponse, error) {
	return &proto.HealthCheckResponse{
		Healthy: true,
		Message: "Service is healthy",
	}, nil
}

// calculateDelayLevel è®¡ç®—å»¶æ—¶ç­‰çº§ï¼ˆä»…ç”¨äºå…¼å®¹æ€§åœºæ™¯ï¼‰
// æ³¨æ„ï¼šå­—èŠ‚äº‘æ”¯æŒä»»æ„ç²¾åº¦å»¶æ—¶ï¼Œä¼˜å…ˆä½¿ç”¨ __STARTDELIVERTIME å±æ€§
func calculateDelayLevel(deliverTime int64) int {
	now := time.Now().UnixMilli()
	delay := deliverTime - now

	// RocketMQå»¶æ—¶ç­‰çº§: 1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h
	delayLevels := []int64{
		1000, 5000, 10000, 30000, 60000, 120000, 180000, 240000,
		300000, 360000, 420000, 480000, 540000, 600000, 1200000,
		1800000, 3600000, 7200000,
	}

	for i, level := range delayLevels {
		if delay <= level {
			return i + 1
		}
	}

	return 18 // æœ€å¤§å»¶æ—¶ç­‰çº§
}
